{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習方法の例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\onoza\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from common.layers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データを読む1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape= (3000, 1, 28, 28)\n",
      "train_label.shape= (3000, 15)\n",
      "train_data_expansion.shape= (15000, 1, 28, 28)\n",
      "train_label_expansion.shape= (15000, 15)\n",
      "train_data.shape= (18000, 1, 28, 28)\n",
      "train_label.shape= (18000, 15)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(\"../1_data/train_data.npy\")\n",
    "train_label = np.load(\"../1_data/train_label.npy\")\n",
    "#train_data = np.load(\"../1_data/imagedatagenerator/train_data_expansion.npy\")\n",
    "#train_label = np.load(\"../1_data/imagedatagenerator/train_label_expansion.npy\")\n",
    "\n",
    "print(\"train_data.shape=\", train_data.shape)\n",
    "print(\"train_label.shape=\", train_label.shape)\n",
    "\n",
    "#データ拡張\n",
    "train_data_expansion = np.load(\"../1_data/imagedatagenerator/train_data_expansion.npy\")\n",
    "train_label_expansion = np.load(\"../1_data/imagedatagenerator/train_label_expansion.npy\")\n",
    "print(\"train_data_expansion.shape=\", train_data_expansion.shape)\n",
    "print(\"train_label_expansion.shape=\", train_label_expansion.shape)\n",
    "\n",
    "train_data = np.concatenate([train_data, train_data_expansion])\n",
    "train_label = np.concatenate([train_label, train_label_expansion])\n",
    "\n",
    "print(\"train_data.shape=\", train_data.shape)\n",
    "print(\"train_label.shape=\", train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def show_image(img): \n",
    "    pil_img = Image.fromarray(img)\n",
    "    plt.imshow(pil_img)\n",
    "    plt.gray()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "#for i in range(3000):\n",
    "#    \n",
    "#    if(0.99<np.random.rand()):        \n",
    "#        img = train_data[i]\n",
    "#        img = img.reshape(28,28)\n",
    "#        img = np.uint8(img*255)\n",
    "#        show_image(img)\n",
    "#\n",
    "#        img = train_data[3000+i]\n",
    "#        img = img.reshape(28,28)\n",
    "#        img = np.uint8(img*255)\n",
    "#        show_image(img)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# 正規化\n",
    "print(train_data.max())\n",
    "print(train_data.min())\n",
    "\n",
    "train_data = (train_data - train_data.min()) / train_data.max()\n",
    "train_data = train_data.astype('float32')\n",
    "# print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配列形式変更\n",
    "#train_data = train_data.reshape(-1, 28*28)\n",
    "#print(\"train_data.shape=\", train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainとtestに分割する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14400, 1, 28, 28) (3600, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, test_size=0.2, random_state=1234, shuffle=True)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0\n",
      "0.8197916666666667 0.7969444444444445\n",
      "epoch=1\n"
     ]
    }
   ],
   "source": [
    "#%%debug\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "lr = 0.01\n",
    "convLayerNum = 5\n",
    "affineLayerNum = 3\n",
    "bnLayerNum = 2\n",
    "\n",
    "# 繰り返し回数\n",
    "xsize = X_train.shape[0]\n",
    "iter_num = np.ceil(xsize / batch_size).astype(np.int)\n",
    "\n",
    "#optimizer = RMSProp(lr=0.001, rho=0.9)\n",
    "optimizer = Adam(lr=0.001, rho1=0.9, rho2=0.999)\n",
    "#optimizer = SGD(lr=0.01)\n",
    "\n",
    "\n",
    "# CNNのオブジェクト生成\n",
    "snet = SimpleConvNet(batch_size, input_dim=(1, 28, 28), \n",
    "                     conv_param={'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                     pool_param={'pool_size':2, 'pad':0, 'stride':2},\n",
    "                     hidden_size=256, output_size=15, weight_init_std=0.01, weight_decay_lambda=0.01)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch=%s\"%epoch)\n",
    "\n",
    "    # シャッフル\n",
    "    idx = np.arange(xsize)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    for it in range(iter_num):\n",
    "        #print(\"it=%s\"%it)\n",
    "\n",
    "        \"\"\"\n",
    "        ランダムなミニバッチを順番に取り出す\n",
    "        \"\"\"\n",
    "        #print(\"it=\", it)\n",
    "        mask = idx[batch_size*it : batch_size*(it+1)]\n",
    "\n",
    "        # ミニバッチの生成\n",
    "        x_train = X_train[mask]\n",
    "        t_train = y_train[mask]\n",
    "\n",
    "        # 勾配の計算 (誤差逆伝播法を用いる) \n",
    "        grads = snet.gradient(x_train, t_train)\n",
    "\n",
    "        # 更新\n",
    "        optimizer.update(snet.params, grads)\n",
    "\n",
    "    ## 学習経過の記録\n",
    "\n",
    "    # 訓練データにおけるloss\n",
    "#     print(\"calculating train_loss\")    \n",
    "    #train_loss.append(snet.loss(X_train,  y_train))\n",
    "\n",
    "#     print(\"calculating test_loss\")\n",
    "    # テストデータにおけるloss\n",
    "    test_loss.append(snet.loss(X_test, y_test))\n",
    "\n",
    "#     print(\"calculating train_accuracy\")\n",
    "    # 訓練データにて精度を確認\n",
    "    train_accuracy.append(snet.accuracy(X_train, y_train))\n",
    "    \n",
    "#     print(\"calculating test_accuracy\")\n",
    "    # テストデータにて精度を算出\n",
    "    test_accuracy.append(snet.accuracy(X_test, y_test))\n",
    "    \n",
    "    print(train_accuracy[-1], test_accuracy[-1])\n",
    "    \n",
    "    #テストデータで98.5%の精度が出たら学習終了\n",
    "    if(test_accuracy[-1] > 0.985):\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lossのグラフ化\n",
    "#df_log = pd.DataFrame({\"train_loss\":train_loss,\n",
    "#             \"test_loss\":test_loss,\n",
    "#             \"train_accuracy\":train_accuracy,\n",
    "#             \"test_accuracy\":test_accuracy})\n",
    "df_log = pd.DataFrame({\"test_loss\":test_loss,\n",
    "                       \"train_accuracy\":train_accuracy,\n",
    "                       \"test_accuracy\":test_accuracy})\n",
    "print(df_log)\n",
    "df_log.plot()\n",
    "plt.ylabel(\"loss or accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#間違った画像を表示\n",
    "snet.display_miss_img(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルの出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"katakana_model.pickle\", \"wb\") as f:\n",
    "#    pickle.dump(snet, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN層のパラメータを抽出\n",
    "for idx in range(1, convLayerNum+1):\n",
    "    with open(\"model_params\\katakana_model_CW\" + str(idx) + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(snet.params['CW' + str(idx)], f)\n",
    "    with open(\"model_params\\katakana_model_Cb\" + str(idx) + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(snet.params['Cb' + str(idx)], f)\n",
    "\n",
    "#全結合層のパラメータを抽出\n",
    "for idx in range(1, affineLayerNum+1):\n",
    "    with open(\"model_params\\katakana_model_AW\" + str(idx) + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(snet.params['AW' + str(idx)], f)\n",
    "    with open(\"model_params\\katakana_model_Ab\" + str(idx) + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(snet.params['Ab' + str(idx)], f)\n",
    "\n",
    "\n",
    "#バッチ正規化レイヤのパラメータを抽出\n",
    "for idx in range(1, bnLayerNum+1):\n",
    "    with open(\"model_params\\katakana_model_gamma\" + str(idx) + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(snet.params['gamma' + str(idx)], f)\n",
    "    with open(\"model_params\\katakana_model_beta\" + str(idx) + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(snet.params['beta' + str(idx)], f)\n",
    "    with open(\"model_params\\katakana_model_moving_mean\" + str(idx) + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(snet.layers['BatchNorm' + str(idx)].moving_mean, f)\n",
    "    with open(\"model_params\\katakana_model_moving_var\" + str(idx) + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(snet.layers['BatchNorm' + str(idx)].moving_var, f)\n",
    "\n",
    "    \n",
    "\n",
    "#print(\"snet.params['beta1']\", snet.params['beta1'])\n",
    "#print(\"snet.params['gamma1']\", snet.params['gamma1'])\n",
    "#print(snet.layers['BatchNorm1'].moving_mean)\n",
    "#print(snet.layers['BatchNorm1'].moving_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
